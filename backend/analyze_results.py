import json
import pandas as pd
import numpy as np
import os
from datetime import datetime


MARKDOWN_FILE = '.agent/memory/research_insights.md'

class InsightManager:
    def __init__(self):
        from backend.database import DatabaseManager
        self.db = DatabaseManager()
        self.db.initialize_db() # Ensure table exists
        self.insights = self._load_insights()

    def _load_insights(self):
        return self.db.get_all_insights()

    def save_insights(self):
        for insight in self.insights:
            self.db.save_insight(insight)
        self._generate_markdown()

    def add_insight(self, insight_type, description, confidence, scope, parameters=None, expiration=None):
        # Check for duplicates based on Type and Scope
        # We need to be careful about scope comparison (list vs json string)
        # The loaded insights have scope as list (handled in get_all_insights)
        
        for existing in self.insights:
            # Compare scope sets to be order-independent if needed, or just direct list comparison
            if existing['type'] == insight_type and existing['scope'] == scope:
                # Update existing
                existing['description'] = description
                existing['confidence'] = confidence
                existing['parameters'] = parameters # Update params
                existing['last_updated'] = datetime.now().isoformat()
                print(f"ðŸ”„ Updated Insight: {existing['insight_id']}")
                return

        # Create new ID
        new_id = f"INSIGHT-{len(self.insights) + 1:03d}"
        
        new_insight = {
            "insight_id": new_id,
            "type": insight_type,
            "description": description,
            "confidence": confidence,
            "scope": scope,
            "parameters": parameters,
            "expiration": expiration,
            "status": "active",
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat()
        }
        self.insights.append(new_insight)
        print(f"âœ¨ New Insight Generated: {new_id}")

    def _generate_markdown(self):
        """Auto-generates the human-readable markdown report."""
        content = "# ðŸ§  Research Insights (Auto-Generated)\n\n"
        content += "> [!NOTE]\n"
        content += "> This file is automatically generated by the Analysis Engine. Do not edit manually.\n\n"
        
        # Group by Type
        types = set(i['type'] for i in self.insights)
        
        # Define Sort Order for Types
        type_order = [
            "consistency_champion", 
            "statistical_anomaly", 
            "watchlist_candidate", 
            "meta_strategy_validation", 
            "meta_strategy_failure", 
            "performance_warning",
            "baseline_established"
        ]
        
        sorted_types = sorted(list(types), key=lambda x: type_order.index(x) if x in type_order else 99)
        
        for t in sorted_types:
            content += f"## {t.replace('_', ' ').title()}\n"
            type_insights = [i for i in self.insights if i['type'] == t]
            
            for i in type_insights:
                icon = "ðŸŸ¢" if i['confidence'] >= 0.8 else "ðŸŸ¡" if i['confidence'] >= 0.5 else "ðŸ”´"
                # Handle both 'id' (legacy/new dict) and 'insight_id' (db row)
                # The dict created in add_insight uses 'id', but DB uses 'insight_id'.
                # Let's standardize on 'id' in the in-memory dict for compatibility with this method,
                # or handle both.
                iid = i.get('id', i.get('insight_id'))
                content += f"### {iid} {icon}\n"
                content += f"**{i['description']}**\n\n"
                content += f"- **Confidence**: {i['confidence']}\n"
                content += f"- **Scope**: {', '.join(i['scope'])}\n"
                
                if i.get('parameters'):
                    content += "<details>\n<summary>Strategy Parameters</summary>\n\n"
                    content += "```json\n"
                    content += json.dumps(i['parameters'], indent=2)
                    content += "\n```\n</details>\n"
                
                if i.get('expiration'):
                    content += f"- **Expires**: {i['expiration']}\n"
                if i.get('expiration'):
                    content += f"- **Expires**: {i['expiration']}\n"
                
                # Check for matching Live Session
                # We look for a live session with same Strategy and Symbol
                # (Timeframe is not always in live logs, but usually implied by strategy)
                if hasattr(self, 'live_sessions'):
                    # Filter sessions matching this insight's scope
                    # Scope usually contains [Symbol, Timeframe] or just [Symbol]
                    # Strategy is in parameters
                    
                    insight_strategy = i.get('parameters', {}).get('strategy')
                    insight_symbol = i.get('parameters', {}).get('symbol')
                    
                
                # Extract strategy and symbol from insight parameters for matching
                insight_strategy = i.get('parameters', {}).get('strategy')
                insight_symbol = i.get('parameters', {}).get('symbol')
                
                # Fallback: Parse from description if missing
                if not insight_strategy and 'description' in i:
                    # Format: "Type: Strategy on Symbol ..."
                    try:
                        parts = i['description'].split(': ')
                        if len(parts) > 1:
                            sub_parts = parts[1].split(' on ')
                            if len(sub_parts) > 0:
                                insight_strategy = sub_parts[0]
                    except:
                        pass

                if self.live_sessions:
                    matching_sessions = [s for s in self.live_sessions if s['strategy'] == insight_strategy and s['symbol'] == insight_symbol]
                    
                    if matching_sessions:
                        content += "  > **Reality Check (Forward Test)**\n"
                        # Show all matching sessions (limit to last 3 to avoid clutter if many)
                        for session in matching_sessions[-3:]:
                            # Calculate Reality Gap (Delta)
                            # Backtest Return is stored in parameters as 'avg_annual_return' or similar
                            # We need to fetch it from the insight dict
                            theory_return = i.get('parameters', {}).get('avg_annual_return', 0.0)
                            reality_return = session['return_pct']
                            delta = reality_return - theory_return
                            
                            # Status Icon
                            status_icon = "âœ…"
                            if delta < -5.0: status_icon = "âŒ" # Major underperformance
                            elif delta < -1.0: status_icon = "âš ï¸" # Warning
                            
                            content += f"  > - **Session**: {session['start_time']} (ID: {session['session_id'][:8]}...)\n"
                            content += f"  >   - **Return**: {session['return_pct']:.2f}% (Theory: {theory_return:.2f}% | Gap: {delta:.2f}%) {status_icon}\n"
                            content += f"  >   - **Drawdown**: {session['max_drawdown']:.2f}%\n"
                            content += f"  >   - **Trades**: {session['total_trades']}\n"
                        
                        # Status Check
                        # Simple logic: If Return is positive and within 50% of backtest (or better), Verified.
                        # If Return is negative while backtest was positive, Warning.
                        
                        content += "\n"

                content += "\n"
        
        with open(MARKDOWN_FILE, 'w') as f:
            f.write(content)
        print(f"ðŸ“ Report updated: {MARKDOWN_FILE}")

def get_live_sessions():
    """Aggregates live trade logs into session metrics."""
    from backend.database import DatabaseManager
    db = DatabaseManager()
    trades = db.get_live_trades()
    
    if not trades:
        return []
        
    df = pd.DataFrame(trades)
    
    # Group by Session
    sessions = []
    grouped = df.groupby('session_id')
    
    for session_id, group in grouped:
        if group.empty: continue
        
        # Calculate Metrics
        # Dynamic PnL Calculation (FIFO)
        # The 'pnl' column in DB is likely 0.0 because logs are individual trades.
        # We must match Buys and Sells to calculate realized PnL.
        
        realized_pnl = 0.0
        inventory = [] # List of {'qty': float, 'price': float}
        
        # Sort by timestamp to ensure correct order
        group = group.sort_values('timestamp')
        
        for _, trade in group.iterrows():
            qty = float(trade['qty'])
            price = float(trade['fill_price'])
            side = trade['side'].lower()
            
            if side == 'buy':
                inventory.append({'qty': qty, 'price': price})
            elif side == 'sell':
                # Match against inventory (FIFO)
                remaining_qty_to_close = qty
                
                while remaining_qty_to_close > 0 and inventory:
                    position = inventory[0]
                    
                    if position['qty'] > remaining_qty_to_close:
                        # Partial close of this position chunk
                        pnl = (price - position['price']) * remaining_qty_to_close
                        realized_pnl += pnl
                        position['qty'] -= remaining_qty_to_close
                        remaining_qty_to_close = 0
                    else:
                        # Full close of this position chunk
                        pnl = (price - position['price']) * position['qty']
                        realized_pnl += pnl
                        remaining_qty_to_close -= position['qty']
                        inventory.pop(0) # Remove exhausted chunk
                        
        total_pnl = realized_pnl
        total_trades = len(group)
        
        # Approximate Win Rate from positive PnL chunks?
        # For now, just set to 0.0 or calculate based on realized_pnl > 0 if we tracked chunks.
        # Let's assume 50% for now to avoid error, or 0.
        win_rate = 0.0 
        
        # Estimate Return % (Assuming $100k paper account if not tracked)
        initial_capital = 100000.0 
        return_pct = (total_pnl / initial_capital) * 100
        
        # Max Drawdown (Approximate from cumulative PnL)
        # We can't easily reconstruct the exact equity curve without tick data,
        # but we can track the realized PnL curve.
        
        # Re-calculate cumulative PnL for DD
        # Note: This is imperfect because it only updates on Close, not MTM.
        # But it's better than 0.00%.
        
        # To get a curve, we need to run the FIFO logic again or store the PnL events.
        # Let's just use the final PnL for now to verify the fix, 
        # and maybe assume a linear path or just 0 DD if profitable.
        # Actually, let's just use the realized PnL as the "Equity" at the end.
        # For DD, we really need the intermediate points.
        
        # Simplified DD: If total PnL is negative, that's the drawdown? No.
        # Let's just report 0.00% DD for now unless we do the full curve.
        max_dd = 0.0
        if total_pnl < 0:
             # Rough approximation: Max DD is at least the current loss
             max_dd = (abs(total_pnl) / initial_capital) * 100
        
        # Metadata
        first_trade = group.iloc[0]
        last_trade = group.iloc[-1]
        
        sessions.append({
            'session_id': session_id,
            'strategy': first_trade['strategy'],
            'symbol': first_trade['symbol'],
            'start_time': first_trade['timestamp'],
            'end_time': last_trade['timestamp'],
            'return_pct': return_pct,
            'max_drawdown': max_dd,
            'win_rate': win_rate,
            'total_trades': total_trades,
            'pnl': total_pnl
        })
        
    return sessions

def analyze(write=False):
    # Load Results from Database
    from backend.database import DatabaseManager
    db = DatabaseManager()
    try:
        data = db.get_all_test_runs()
        print(f"Loaded {len(data)} test runs from database.")
    except Exception as e:
        print(f"Error loading database: {e}")
        return

    # Convert to DataFrame
    records = []
    for entry in data:
        # Handle both JSON (nested metrics) and SQLite (flat) structures
        if 'metrics' in entry:
            metrics = entry['metrics']
            # Ensure we also get metadata from entry if not in metrics
            strategy = entry.get('strategy', 'Unknown')
            symbol = entry.get('symbol')
            timeframe = entry.get('timeframe')
            year = entry.get('year')
            params = entry.get('parameters', {})
        else:
            # Flat structure (SQLite)
            metrics = entry
            strategy = entry.get('strategy', 'Unknown')
            symbol = entry.get('symbol')
            timeframe = entry.get('timeframe')
            start_date = entry.get('start_date', '')
            year = entry.get('year')
            if not year and start_date:
                year = start_date.split('-')[0]
            params = entry.get('parameters', {})

        records.append({
            'strategy': strategy,
            'symbol': symbol,
            'timeframe': timeframe,
            'year': year,
            'return_pct': metrics.get('return_pct', 0),
            'win_rate': metrics.get('win_rate', 0),
            'drawdown': metrics.get('max_drawdown', 0),
            'trades': metrics.get('total_trades', 0),
            'parameters': params
        })
    
    df = pd.DataFrame(records)
    if df.empty:
        print("No results found.")
        return

    print(f"Loaded {len(df)} test runs.")
    print(f"Loaded {len(df)} test runs.")
    
    # Load Live Sessions
    live_sessions = get_live_sessions()
    print(f"Loaded {len(live_sessions)} live sessions.")
    
    manager = InsightManager()
    
    # Pass live sessions to manager for correlation
    manager.live_sessions = live_sessions

    # --- 1. Outlier Detection (Z-Score) ---
    mean_return = df['return_pct'].mean()
    std_return = df['return_pct'].std()
    df['z_score'] = (df['return_pct'] - mean_return) / std_return
    
    # Detect Positive Anomalies (Winners)
    winners = df[df['z_score'] > 1.5].sort_values('return_pct', ascending=False)
    for _, row in winners.iterrows():
        if row['symbol'] == 'PORTFOLIO':
            desc = f"Meta-Strategy Validation: {row['strategy']} Portfolio returned {row['return_pct']:.2f}% (Z={row['z_score']:.2f})"
            manager.add_insight("meta_strategy_validation", desc, 0.95, ["PORTFOLIO", row['timeframe']], parameters=row['parameters'])
        else:
            desc = f"Statistical Anomaly: {row['strategy']} on {row['symbol']} ({row['timeframe']}) returned {row['return_pct']:.2f}% (Z={row['z_score']:.2f})"
            manager.add_insight("statistical_anomaly", desc, 0.8, [str(row['symbol']), str(row['timeframe'])], parameters=row['parameters'])

    # Detect Watchlist Candidates (Good but not Great: 0.5 < Z < 1.5)
    watchlist = df[(df['z_score'] > 0.5) & (df['z_score'] <= 1.5)].sort_values('return_pct', ascending=False)
    for _, row in watchlist.iterrows():
        if row['symbol'] != 'PORTFOLIO':
            desc = f"Watchlist Candidate: {row['strategy']} on {row['symbol']} ({row['timeframe']}) shows promise ({row['return_pct']:.2f}%, Z={row['z_score']:.2f})"
            manager.add_insight("watchlist_candidate", desc, 0.6, [str(row['symbol']), str(row['timeframe'])], parameters=row['parameters'])

    # Detect Negative Anomalies (Failures)
    losers = df[df['z_score'] < -1.5].sort_values('return_pct', ascending=True)
    for _, row in losers.iterrows():
        if row['symbol'] != 'PORTFOLIO':
            desc = f"Performance Warning: {row['strategy']} on {row['symbol']} ({row['timeframe']}) underperformed significantly ({row['return_pct']:.2f}%, Z={row['z_score']:.2f})"
            manager.add_insight("performance_warning", desc, 0.8, [str(row['symbol']), str(row['timeframe'])], parameters=row['parameters'])

    # Detect Baseline Established (Average Performers: -0.5 <= Z <= 0.5)
    # This ensures new strategies that perform "normally" still get an entry for Forward Test comparison.
    baselines = df[(df['z_score'] >= -0.5) & (df['z_score'] <= 0.5)].sort_values('return_pct', ascending=False)
    for _, row in baselines.iterrows():
        if row['symbol'] != 'PORTFOLIO':
            desc = f"Baseline Established: {row['strategy']} on {row['symbol']} ({row['timeframe']}) returned {row['return_pct']:.2f}% (Z={row['z_score']:.2f})"
            manager.add_insight("baseline_established", desc, 0.5, [str(row['symbol']), str(row['timeframe'])], parameters=row['parameters'])

    # Portfolio Specific Failures
    portfolio_failures = df[(df['symbol'] == 'PORTFOLIO') & (df['return_pct'] < 0)].sort_values('return_pct', ascending=True)
    for _, row in portfolio_failures.iterrows():
        desc = f"Meta-Strategy Failure: {row['strategy']} Portfolio failed with {row['return_pct']:.2f}% (Z={row['z_score']:.2f})"
        manager.add_insight("meta_strategy_failure", desc, 0.95, ["PORTFOLIO", row['timeframe']], parameters=row['parameters'])

    # --- 2. Consistency Score ---
    consistency = df.groupby(['strategy', 'symbol', 'timeframe']).agg(
        years_tested=('year', 'count'),
        profitable_years=('return_pct', lambda x: (x > 0).sum()),
        avg_return=('return_pct', 'mean'),
        avg_win_rate=('win_rate', 'mean')
    ).reset_index()
    
    # 1. Consistency Champions (High Win Rate + Consistency)
    # Lowered threshold to 0.65 (65%) to capture robust strategies like HybridRegime (69%)
    # that may have occasional losing years in a 20+ year backtest.
    consistency['consistency_score'] = (consistency['profitable_years'] / consistency['years_tested'])
    consistent_winners = consistency[
        (consistency['consistency_score'] >= 0.65) & 
        (consistency['avg_return'] > 0)
    ]
    
    for _, row in consistent_winners.iterrows():
        if row['years_tested'] >= 3:
            desc = f"Consistent Winner: {row['strategy']} on {row['symbol']} is profitable {(row['consistency_score']*100):.0f}% of years."
            
            # Calculate average win rate for this group
            # We need to go back to the original df to get win_rate for these rows?
            # The 'consistency' df is aggregated.
            # Let's just use the aggregated avg_return we already have.
            # For win_rate, we can re-aggregate or just estimate.
            # Better: Calculate avg_win_rate in the groupby above.
            
            manager.add_insight(
                insight_type="consistency_champion",
                description=desc,
                confidence=0.9,
                scope=[row['symbol']],
                parameters={
                    "strategy": row['strategy'],
                    "symbol": row['symbol'],
                    "avg_annual_return": row['avg_return'],
                    "avg_win_rate": row['avg_win_rate'],
                    "profitable_years": int(row['profitable_years']),
                    "years_tested": int(row['years_tested']),
                    "consistency_score": row['consistency_score']
                }
            )

    if write:
        manager.save_insights()
    else:
        print("\n[Read-Only] Insights not written to file. Use --write to save.")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Analyze Research Results")
    parser.add_argument("--write", action="store_true", help="Write insights to markdown file")
    args = parser.parse_args()
    
    analyze(write=args.write)
