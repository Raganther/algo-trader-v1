import json
import pandas as pd
import numpy as np
import os
from datetime import datetime


MARKDOWN_FILE = '.agent/memory/research_insights.md'

class InsightManager:
    def __init__(self):
        from backend.database import DatabaseManager
        self.db = DatabaseManager()
        self.db.initialize_db() # Ensure table exists
        self.insights = self._load_insights()

    def _load_insights(self):
        return self.db.get_all_insights()

    def save_insights(self):
        for insight in self.insights:
            self.db.save_insight(insight)
        self._generate_markdown()

    def add_insight(self, insight_type, description, confidence, scope, parameters=None, expiration=None):
        # Check for duplicates based on Type and Scope
        # We need to be careful about scope comparison (list vs json string)
        # The loaded insights have scope as list (handled in get_all_insights)
        
        for existing in self.insights:
            # Compare scope sets to be order-independent if needed, or just direct list comparison
            if existing['type'] == insight_type and existing['scope'] == scope:
                # Update existing
                existing['description'] = description
                existing['confidence'] = confidence
                existing['parameters'] = parameters # Update params
                existing['last_updated'] = datetime.now().isoformat()
                print(f"üîÑ Updated Insight: {existing['insight_id']}")
                return

        # Create new ID
        new_id = f"INSIGHT-{len(self.insights) + 1:03d}"
        
        new_insight = {
            "insight_id": new_id,
            "type": insight_type,
            "description": description,
            "confidence": confidence,
            "scope": scope,
            "parameters": parameters,
            "expiration": expiration,
            "status": "active",
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat()
        }
        self.insights.append(new_insight)
        print(f"‚ú® New Insight Generated: {new_id}")

    def _generate_markdown(self):
        """Auto-generates the human-readable markdown report (Hybrid Layout)."""
        content = "# üß† Research Insights (Hybrid Layout)\n\n"
        content += "> [!NOTE]\n"
        content += "> This file is automatically generated by the Analysis Engine. Do not edit manually.\n\n"
        
        # 1. Group Insights by Strategy & Symbol
        # We need to collect all insights related to a specific Strategy+Symbol pair.
        grouped_insights = {}
        
        for i in self.insights:
            # Extract Strategy & Symbol
            params = i.get('parameters', {})
            strategy = params.get('strategy')
            symbol = params.get('symbol')
            
            # Fallback parsing from description if params missing
            if not strategy or not symbol:
                try:
                    if 'on' in i['description']:
                        parts = i['description'].split(' on ')
                        # "Type: Strategy on Symbol ..."
                        left_parts = parts[0].split(': ')
                        strategy = left_parts[-1].strip()
                        symbol = parts[1].split(' ')[0].strip()
                except:
                    pass
            
            if not strategy or not symbol:
                continue # Skip if we can't identify
                
            key = (strategy, symbol)
            if key not in grouped_insights:
                grouped_insights[key] = []
            grouped_insights[key].append(i)
            
        # 2. Sort Groups by "Best" Insight Confidence/Return
        # We want "Consistency Champions" and "Anomalies" at the top.
        sorted_keys = sorted(grouped_insights.keys(), key=lambda k: (
            max([x['confidence'] for x in grouped_insights[k]]),
            max([x.get('parameters', {}).get('avg_annual_return', x.get('parameters', {}).get('return_pct', -999)) for x in grouped_insights[k]])
        ), reverse=True)
        
        for i, (strategy, symbol) in enumerate(sorted_keys):
            group = grouped_insights[(strategy, symbol)]
            
            # Determine Status
            # If any insight is > 0.8 confidence, it's Green.
            max_conf = max([x['confidence'] for x in group])
            status_icon = "üü¢" if max_conf >= 0.8 else "üü°" if max_conf >= 0.5 else "üî¥"
            
            # Check Reality Gap for Header
            reality_gap_str = "N/A"
            reality_status = ""
            
            # Find matching live sessions
            matching_sessions = []
            if hasattr(self, 'live_sessions') and self.live_sessions:
                matching_sessions = [s for s in self.live_sessions if s['strategy'] == strategy and s['symbol'] == symbol]
                
            if matching_sessions:
                # Sort by start_time to ensure we get the true chronological order
                matching_sessions.sort(key=lambda x: x['start_time'])
                
                # Use the latest session for the header status
                latest_session = matching_sessions[-1]
                # Find the "Theory" win rate from the Best Backtest (highest return)
                best_backtest = sorted(group, key=lambda x: x.get('parameters', {}).get('return_pct', -999), reverse=True)[0]
                theory_wr = best_backtest.get('parameters', {}).get('win_rate', 0.0)
                
                # If theory_wr is missing (e.g. consistency insight), try to find a specific run
                if theory_wr == 0.0:
                     # Look for any run with win_rate
                     for g in group:
                         wr = g.get('parameters', {}).get('win_rate', 0.0)
                         if wr > 0:
                             theory_wr = wr
                             break
                
                # Scale if needed (0.66 -> 66.0)
                if theory_wr <= 1.0: theory_wr *= 100
                
                reality_wr = latest_session['win_rate']
                delta = reality_wr - theory_wr
                
                gap_icon = "‚úÖ"
                if abs(delta) > 20.0: gap_icon = "‚ùå"
                elif abs(delta) > 10.0: gap_icon = "‚ö†Ô∏è"
                
                reality_gap_str = f"{delta:+.1f}%"
                reality_status = gap_icon

            content += f"## {i+1}. {strategy} on {symbol}\n"
            content += f"> **Status**: {status_icon} | **Reality Gap**: {reality_gap_str} {reality_status}\n\n"
            
            # A. Best Backtest (Theory)
            # Prioritize "Consistency Champion" if exists, else Highest Return from ANY backtest type
            champion = next((x for x in group if x['type'] == 'consistency_champion'), None)
            
            # Get all non-consistency runs (anomalies, baselines, watchlist, etc.)
            all_runs = [x for x in group if x['type'] != 'consistency_champion']
            sorted_runs = sorted(all_runs, key=lambda x: x.get('parameters', {}).get('return_pct', -999), reverse=True)
            best_run = sorted_runs[0] if sorted_runs else None
            
            if champion:
                p = champion.get('parameters', {})
                content += "### üèÜ Best Backtest (Theory: Consistency)\n"
                content += f"**Avg Return**: {p.get('avg_annual_return', 0):.2f}% | **Avg Win Rate**: {p.get('avg_win_rate', 0)*100:.1f}%\n"
                content += f"- **Confidence**: {champion['confidence']} (Consistency Champion)\n"
                content += f"- **Consistency**: Profitable {p.get('profitable_years', 0)}/{p.get('years_tested', 0)} years ({p.get('consistency_score', 0)*100:.0f}%)\n\n"
            elif best_run:
                p = best_run.get('parameters', {})
                wr_val = p.get('win_rate', 0)
                wr_disp = wr_val * 100 if wr_val <= 1.0 else wr_val
                
                content += "### üèÜ Best Backtest (Theory: Highest Return)\n"
                content += f"**Return**: {p.get('return_pct', 0):.2f}% | **Win Rate**: {wr_disp:.1f}% | **Drawdown**: {p.get('max_drawdown', 0):.2f}%\n"
                content += f"- **Confidence**: {best_run['confidence']} ({best_run['type'].replace('_', ' ').title()})\n"
                content += f"- **Timeframe**: {p.get('timeframe', 'N/A')}\n"
                content += f"- **Parameters**: `{json.dumps(p)}`\n\n"
            
            # B. Reality Check (Forward Test)
            if matching_sessions:
                content += "### üß™ Reality Check (Forward Test)\n"
                for session in matching_sessions[-3:]: # Last 3
                    # Recalculate Delta for specific session
                    # Use the theory WR from the best run we displayed above
                    theory_wr_disp = 0.0
                    if champion: 
                        theory_wr_disp = champion.get('parameters', {}).get('avg_win_rate', 0)
                        if theory_wr_disp <= 1.0: theory_wr_disp *= 100
                    elif best_run: 
                        # Try to get win_rate from best_run, fallback to finding ANY win_rate in group
                        wr = best_run.get('parameters', {}).get('win_rate', 0)
                        if wr == 0:
                             for g in group:
                                 w = g.get('parameters', {}).get('win_rate', 0)
                                 if w > 0:
                                     wr = w
                                     break
                        theory_wr_disp = wr * 100 if wr <= 1.0 else wr 
                    
                    reality_wr = session['win_rate']
                    delta = reality_wr - theory_wr_disp
                    
                    s_icon = "‚úÖ"
                    if abs(delta) > 20.0: s_icon = "‚ùå"
                    elif abs(delta) > 10.0: s_icon = "‚ö†Ô∏è"
                    
                    content += f"- **Session**: {session['start_time'].split('T')[0]} (ID: {session['session_id'][:8]}...)\n"
                    content += f"  - **Win Rate**: {reality_wr:.1f}% (Theory: {theory_wr_disp:.1f}% | Gap: {delta:+.1f}%) {s_icon}\n"
                    content += f"  - **Return**: {session['return_pct']:.2f}% | **Trades**: {session['total_trades']}\n"
                content += "\n"
                
            # C. Iteration History (Table)
            # List all insights for this group (excluding the one we just showed as 'Best' if we want, or show all)
            # Let's show all "Runs" (Statistical Anomalies, Watchlist, Baselines) in a table.
            # Consistency insights don't fit well in the table (aggregated).
            
            runs = [x for x in group if x['type'] in ['statistical_anomaly', 'watchlist_candidate', 'baseline_established', 'performance_warning']]
            if runs:
                content += "### üìú Iteration History\n"
                content += "| Type | TF | Return | Win Rate | Params |\n"
                content += "| :--- | :--- | :--- | :--- | :--- |\n"
                
                # Sort by Return
                runs.sort(key=lambda x: x.get('parameters', {}).get('return_pct', -999), reverse=True)
                
                for r in runs:
                    p = r.get('parameters', {})
                    # Shorten Params for Table
                    # Remove strategy/symbol/metrics to save space
                    short_p = {k:v for k,v in p.items() if k not in ['strategy', 'symbol', 'return_pct', 'win_rate', 'max_drawdown', 'total_trades', 'timeframe', 'year']}
                    param_str = json.dumps(short_p)
                    
                    wr_val = p.get('win_rate', 0)
                    wr_disp = wr_val * 100 if wr_val <= 1.0 else wr_val
                    
                    # Icons
                    icon = "üü¢" if r['confidence'] >= 0.8 else "üü°" if r['confidence'] >= 0.6 else "‚ö™"
                    if r['type'] == 'performance_warning': icon = "üî¥"
                    
                    content += f"| {icon} {r['type'].split('_')[0].title()} | {p.get('timeframe', 'N/A')} | **{p.get('return_pct', 0):.2f}%** | {wr_disp:.0f}% | `{param_str}` |\n"
                content += "\n"
                
            content += "---\n\n"
        
        with open(MARKDOWN_FILE, 'w') as f:
            f.write(content)
        print(f"üìù Report updated: {MARKDOWN_FILE}")

def get_live_sessions():
    """Aggregates live trade logs into session metrics."""
    from backend.database import DatabaseManager
    db = DatabaseManager()
    trades = db.get_live_trades()
    
    if not trades:
        return []
        
    df = pd.DataFrame(trades)
    
    # Group by Session
    sessions = []
    grouped = df.groupby('session_id')
    
    for session_id, group in grouped:
        if group.empty: continue
        
        # Calculate Metrics
        # Dynamic PnL Calculation (FIFO)
        # The 'pnl' column in DB is likely 0.0 because logs are individual trades.
        # We must match Buys and Sells to calculate realized PnL.
        
        realized_pnl = 0.0
        inventory = [] 
        wins = 0
        closed_trades = 0
        
        group = group.sort_values('timestamp')
        
        for _, trade in group.iterrows():
            qty = float(trade['qty'])
            price = float(trade['fill_price'])
            side = trade['side'].lower()
            
            if side == 'buy':
                inventory.append({'qty': qty, 'price': price})
            elif side == 'sell':
                remaining_qty_to_close = qty
                trade_pnl = 0.0
                
                while remaining_qty_to_close > 0 and inventory:
                    position = inventory[0]
                    
                    if position['qty'] > remaining_qty_to_close:
                        chunk_pnl = (price - position['price']) * remaining_qty_to_close
                        trade_pnl += chunk_pnl
                        position['qty'] -= remaining_qty_to_close
                        remaining_qty_to_close = 0
                    else:
                        chunk_pnl = (price - position['price']) * position['qty']
                        trade_pnl += chunk_pnl
                        remaining_qty_to_close -= position['qty']
                        inventory.pop(0)
                
                realized_pnl += trade_pnl
                closed_trades += 1
                if trade_pnl > 0:
                    wins += 1
                    
        total_pnl = realized_pnl
        total_trades = len(group)
        win_rate = (wins / closed_trades * 100) if closed_trades > 0 else 0.0
        
        # Estimate Return % (Assuming $100k paper account if not tracked)
        initial_capital = 100000.0 
        return_pct = (total_pnl / initial_capital) * 100
        
        # Max Drawdown (Approximate from cumulative PnL)
        # We can't easily reconstruct the exact equity curve without tick data,
        # but we can track the realized PnL curve.
        
        # Re-calculate cumulative PnL for DD
        # Note: This is imperfect because it only updates on Close, not MTM.
        # But it's better than 0.00%.
        
        # To get a curve, we need to run the FIFO logic again or store the PnL events.
        # Let's just use the final PnL for now to verify the fix, 
        # and maybe assume a linear path or just 0 DD if profitable.
        # Actually, let's just use the realized PnL as the "Equity" at the end.
        # For DD, we really need the intermediate points.
        
        # Simplified DD: If total PnL is negative, that's the drawdown? No.
        # Let's just report 0.00% DD for now unless we do the full curve.
        max_dd = 0.0
        if total_pnl < 0:
             # Rough approximation: Max DD is at least the current loss
             max_dd = (abs(total_pnl) / initial_capital) * 100
        
        # Metadata
        first_trade = group.iloc[0]
        last_trade = group.iloc[-1]
        
        sessions.append({
            'session_id': session_id,
            'strategy': first_trade['strategy'],
            'symbol': first_trade['symbol'],
            'start_time': first_trade['timestamp'],
            'end_time': last_trade['timestamp'],
            'return_pct': return_pct,
            'max_drawdown': max_dd,
            'win_rate': win_rate,
            'total_trades': total_trades,
            'pnl': total_pnl
        })
        
    return sessions

def analyze(write=False):
    # Load Results from Database
    from backend.database import DatabaseManager
    db = DatabaseManager()
    try:
        data = db.get_all_test_runs()
        print(f"Loaded {len(data)} test runs from database.")
    except Exception as e:
        print(f"Error loading database: {e}")
        return

    # Convert to DataFrame
    records = []
    for entry in data:
        # Handle both JSON (nested metrics) and SQLite (flat) structures
        if 'metrics' in entry:
            metrics = entry['metrics']
            # Ensure we also get metadata from entry if not in metrics
            strategy = entry.get('strategy', 'Unknown')
            symbol = entry.get('symbol')
            timeframe = entry.get('timeframe')
            year = entry.get('year')
            params = entry.get('parameters', {})
        else:
            # Flat structure (SQLite)
            metrics = entry
            strategy = entry.get('strategy', 'Unknown')
            symbol = entry.get('symbol')
            timeframe = entry.get('timeframe')
            start_date = entry.get('start_date', '')
            year = entry.get('year')
            if not year and start_date:
                year = start_date.split('-')[0]
            params = entry.get('parameters', {})

        records.append({
            'strategy': strategy,
            'symbol': symbol,
            'timeframe': timeframe,
            'year': year,
            'return_pct': metrics.get('return_pct', 0),
            'win_rate': metrics.get('win_rate', 0),
            'drawdown': metrics.get('max_drawdown', 0),
            'trades': metrics.get('total_trades', 0),
            'parameters': params
        })
    
    df = pd.DataFrame(records)
    if df.empty:
        print("No results found.")
        return

    print(f"Loaded {len(df)} test runs.")
    print(f"Loaded {len(df)} test runs.")
    
    # Load Live Sessions
    live_sessions = get_live_sessions()
    print(f"Loaded {len(live_sessions)} live sessions.")
    
    manager = InsightManager()
    
    # Pass live sessions to manager for correlation
    manager.live_sessions = live_sessions

    # --- 1. Outlier Detection (Z-Score) ---
    mean_return = df['return_pct'].mean()
    std_return = df['return_pct'].std()
    df['z_score'] = (df['return_pct'] - mean_return) / std_return
    
    # Helper to prepare params with metrics
    def prepare_params(row):
        p = row['parameters'].copy() if isinstance(row['parameters'], dict) else {}
        p['return_pct'] = row['return_pct']
        p['win_rate'] = row['win_rate']
        p['max_drawdown'] = row['drawdown']
        p['total_trades'] = row['trades']
        p['timeframe'] = row['timeframe']
        p['year'] = row['year']
        p['strategy'] = row['strategy']
        p['symbol'] = row['symbol']
        return p

    # Detect Positive Anomalies (Winners)
    winners = df[df['z_score'] > 1.5].sort_values('return_pct', ascending=False)
    for _, row in winners.iterrows():
        params = prepare_params(row)
        if row['symbol'] == 'PORTFOLIO':
            desc = f"Meta-Strategy Validation: {row['strategy']} Portfolio returned {row['return_pct']:.2f}% (Z={row['z_score']:.2f})"
            manager.add_insight("meta_strategy_validation", desc, 0.95, ["PORTFOLIO", row['timeframe']], parameters=params)
        else:
            desc = f"Statistical Anomaly: {row['strategy']} on {row['symbol']} ({row['timeframe']}) returned {row['return_pct']:.2f}% (Z={row['z_score']:.2f})"
            manager.add_insight("statistical_anomaly", desc, 0.8, [str(row['symbol']), str(row['timeframe'])], parameters=params)

    # Detect Watchlist Candidates (Good but not Great: 0.5 < Z < 1.5)
    watchlist = df[(df['z_score'] > 0.5) & (df['z_score'] <= 1.5)].sort_values('return_pct', ascending=False)
    for _, row in watchlist.iterrows():
        params = prepare_params(row)
        if row['symbol'] != 'PORTFOLIO':
            desc = f"Watchlist Candidate: {row['strategy']} on {row['symbol']} ({row['timeframe']}) shows promise ({row['return_pct']:.2f}%, Z={row['z_score']:.2f})"
            manager.add_insight("watchlist_candidate", desc, 0.6, [str(row['symbol']), str(row['timeframe'])], parameters=params)

    # Detect Negative Anomalies (Failures)
    losers = df[df['z_score'] < -1.5].sort_values('return_pct', ascending=True)
    for _, row in losers.iterrows():
        params = prepare_params(row)
        if row['symbol'] != 'PORTFOLIO':
            desc = f"Performance Warning: {row['strategy']} on {row['symbol']} ({row['timeframe']}) underperformed significantly ({row['return_pct']:.2f}%, Z={row['z_score']:.2f})"
            manager.add_insight("performance_warning", desc, 0.8, [str(row['symbol']), str(row['timeframe'])], parameters=params)

    # Detect Baseline Established (Average Performers: -0.5 <= Z <= 0.5)
    # This ensures new strategies that perform "normally" still get an entry for Forward Test comparison.
    baselines = df[(df['z_score'] >= -0.5) & (df['z_score'] <= 0.5)].sort_values('return_pct', ascending=False)
    for _, row in baselines.iterrows():
        params = prepare_params(row)
        if row['symbol'] != 'PORTFOLIO':
            desc = f"Baseline Established: {row['strategy']} on {row['symbol']} ({row['timeframe']}) returned {row['return_pct']:.2f}% (Z={row['z_score']:.2f})"
            manager.add_insight("baseline_established", desc, 0.5, [str(row['symbol']), str(row['timeframe'])], parameters=params)

    # Portfolio Specific Failures
    portfolio_failures = df[(df['symbol'] == 'PORTFOLIO') & (df['return_pct'] < 0)].sort_values('return_pct', ascending=True)
    for _, row in portfolio_failures.iterrows():
        params = prepare_params(row)
        desc = f"Meta-Strategy Failure: {row['strategy']} Portfolio failed with {row['return_pct']:.2f}% (Z={row['z_score']:.2f})"
        manager.add_insight("meta_strategy_failure", desc, 0.95, ["PORTFOLIO", row['timeframe']], parameters=params)

    # --- 2. Consistency Score ---
    consistency = df.groupby(['strategy', 'symbol', 'timeframe']).agg(
        years_tested=('year', 'count'),
        profitable_years=('return_pct', lambda x: (x > 0).sum()),
        avg_return=('return_pct', 'mean'),
        avg_win_rate=('win_rate', 'mean')
    ).reset_index()
    
    # 1. Consistency Champions (High Win Rate + Consistency)
    # Lowered threshold to 0.65 (65%) to capture robust strategies like HybridRegime (69%)
    # that may have occasional losing years in a 20+ year backtest.
    consistency['consistency_score'] = (consistency['profitable_years'] / consistency['years_tested'])
    consistent_winners = consistency[
        (consistency['consistency_score'] >= 0.65) & 
        (consistency['avg_return'] > 0)
    ]
    
    for _, row in consistent_winners.iterrows():
        if row['years_tested'] >= 3:
            desc = f"Consistent Winner: {row['strategy']} on {row['symbol']} is profitable {(row['consistency_score']*100):.0f}% of years."
            
            # Calculate average win rate for this group
            # We need to go back to the original df to get win_rate for these rows?
            # The 'consistency' df is aggregated.
            # Let's just use the aggregated avg_return we already have.
            # For win_rate, we can re-aggregate or just estimate.
            # Better: Calculate avg_win_rate in the groupby above.
            
            manager.add_insight(
                insight_type="consistency_champion",
                description=desc,
                confidence=0.9,
                scope=[row['symbol']],
                parameters={
                    "strategy": row['strategy'],
                    "symbol": row['symbol'],
                    "avg_annual_return": row['avg_return'],
                    "avg_win_rate": row['avg_win_rate'],
                    "profitable_years": int(row['profitable_years']),
                    "years_tested": int(row['years_tested']),
                    "consistency_score": row['consistency_score']
                }
            )

    if write:
        manager.save_insights()
    else:
        print("\n[Read-Only] Insights not written to file. Use --write to save.")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Analyze Research Results")
    parser.add_argument("--write", action="store_true", help="Write insights to markdown file")
    args = parser.parse_args()
    
    analyze(write=args.write)
